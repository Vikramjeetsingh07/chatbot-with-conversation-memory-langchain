{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import streamlit as st\n",
    "import re\n",
    "import time\n",
    "from io import BytesIO\n",
    "from typing import Any, Dict, List\n",
    "import openai\n",
    "from langchain import LLMChain, OpenAI\n",
    "from langchain.agents import AgentExecutor, Tool, ZeroShotAgent\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import VectorStore\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from pypdf import PdfReader\n",
    "\n",
    "@st.cache_data\n",
    "def parse_pdf(file: BytesIO) -> List[str]:\n",
    "    pdf = PdfReader(file)\n",
    "    output = []\n",
    "    for page in pdf.pages:\n",
    "        text = page.extract_text()\n",
    "        \n",
    "        text = re.sub(r\"(\\w+)-\\n(\\w+)\", r\"\\1\\2\", text)\n",
    "        \n",
    "        text = re.sub(r\"(?<!\\n\\s)\\n(?!\\s\\n)\", \" \", text.strip())\n",
    "        \n",
    "        text = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", text)\n",
    "        output.append(text)\n",
    "    return output\n",
    "\n",
    "\n",
    "@st.cache_data\n",
    "def text_to_docs(text: str) -> List[Document]:\n",
    "    \n",
    "    if isinstance(text, str):\n",
    "        \n",
    "        text = [text]\n",
    "    page_docs = [Document(page_content=page) for page in text]\n",
    "\n",
    "    \n",
    "    for i, doc in enumerate(page_docs):\n",
    "        doc.metadata[\"page\"] = i + 1\n",
    "\n",
    "    \n",
    "    doc_chunks = []\n",
    "\n",
    "    for doc in page_docs:\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=4000,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
    "            chunk_overlap=0,\n",
    "        )\n",
    "        chunks = text_splitter.split_text(doc.page_content)\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            doc = Document(\n",
    "                page_content=chunk, metadata={\"page\": doc.metadata[\"page\"], \"chunk\": i}\n",
    "            )\n",
    "            \n",
    "            doc.metadata[\"source\"] = f\"{doc.metadata['page']}-{doc.metadata['chunk']}\"\n",
    "            doc_chunks.append(doc)\n",
    "    return doc_chunks\n",
    "\n",
    "\n",
    "@st.cache_data\n",
    "def test_embed():\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=api)\n",
    "    \n",
    "    with st.spinner(\"Processing...\"):\n",
    "        index = FAISS.from_documents(pages, embeddings)\n",
    "    st.success(\"Embeddings generated successfully.\", icon=\"âœ…\")\n",
    "    return index\n",
    "st.title(\" PDF Chatgpt \")\n",
    "st.sidebar.markdown(\n",
    "    \"\"\"\n",
    "    ### Order:\n",
    "    1. Upload PDF File that you would like to talk to:-\n",
    "    2. Enter Your openAI Key\n",
    "    3. Ask your pdf questions\n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "uploaded_file = st.file_uploader(\"**Upload the PDF File you would like to have a chat**\", type=[\"pdf\"])\n",
    "if uploaded_file:\n",
    "    name_of_file = uploaded_file.name\n",
    "    doc = parse_pdf(uploaded_file)\n",
    "    pages = text_to_docs(doc)\n",
    "    if pages:\n",
    "        with st.expander(\"Show Page Content\", expanded=False):\n",
    "            page_sel = st.number_input(\n",
    "                label=\"Select Page\", min_value=1, max_value=len(pages), step=1\n",
    "            )\n",
    "            pages[page_sel - 1]\n",
    "api = st.text_input(\n",
    "            \"**Enter OpenAI API Key**\",\n",
    "            type=\"password\",\n",
    "            placeholder=\"sk-\",\n",
    "            help=\"https://platform.openai.com/account/api-keys\",\n",
    "        )\n",
    "if api:\n",
    "        index = test_embed()\n",
    "        qa = RetrievalQA.from_chain_type(\n",
    "        llm=OpenAI(openai_api_key=api),\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=index.as_retriever(),\n",
    "        )\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"State of Union QA System\",\n",
    "                func=qa.run,\n",
    "                description=\"Useful for when you need to answer questions about the aspects asked. Input may be a partial or fully formed question.\",\n",
    "            )\n",
    "        ]\n",
    "        prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can based on the context and memory available. \n",
    "                You have access to a single tool:\"\"\"\n",
    "        suffix = \"\"\"Begin!\"\n",
    "        {chat_history}\n",
    "        Question: {input}\n",
    "            {agent_scratchpad}\"\"\"\n",
    "        prompt = ZeroShotAgent.create_prompt(\n",
    "            tools,\n",
    "            prefix=prefix,\n",
    "            suffix=suffix,\n",
    "            input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"]\n",
    "        )\n",
    "        if \"memory\" not in st.session_state:\n",
    "            st.session_state.memory = ConversationBufferMemory(\n",
    "                memory_key=\"chat_history\"\n",
    "            )\n",
    "        llm_chain = LLMChain(\n",
    "            llm=OpenAI(\n",
    "                temperature=0, openai_api_key=api, model_name=\"gpt-3.5-turbo\"\n",
    "            ),\n",
    "            prompt=prompt,\n",
    "        )\n",
    "        agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
    "        agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "                agent=agent, tools=tools, verbose=True, memory=st.session_state.memory\n",
    "            )\n",
    "        query = st.text_input(\n",
    "                \"**Ask me anything?**\",\n",
    "                placeholder=\"Ask me anything from {}\".format(name_of_file),\n",
    "            )\n",
    "\n",
    "        if query:\n",
    "            with st.spinner(\n",
    "                 \"Generating Answer to your Query : `{}` \".format(query)\n",
    "            ):\n",
    "                res = agent_chain.run(query)\n",
    "                st.info(res, icon=\"ðŸ¤–\")\n",
    "\n",
    "        with st.expander(\"History/Memory\"):\n",
    "            st.session_state.memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
